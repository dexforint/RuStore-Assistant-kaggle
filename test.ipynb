{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-large-v3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/4f/e9/4fe94fab3c6a8bf97c3289fc6feb023e1504259a53971018d4b19f2f7ed06185/69f74147e3334731bc3a76048724833325d2ec74642fb52620eda87352e3d4f1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.bin%3B+filename%3D%22model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1720543701&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDU0MzcwMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRmL2U5LzRmZTk0ZmFiM2M2YThiZjk3YzMyODlmYzZmZWIwMjNlMTUwNDI1OWE1Mzk3MTAxOGQ0YjE5ZjJmN2VkMDYxODUvNjlmNzQxNDdlMzMzNDczMWJjM2E3NjA0ODcyNDgzMzMyNWQyZWM3NDY0MmZiNTI2MjBlZGE4NzM1MmUzZDRmMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=B83viReFoJgzkpt%7Ej0%7E93lTXThXkc6LgseDICUy3FEd8iJakLQf0pY7PLXZ8q5-YrZcP8dJtLDBCXBy2Gq29Oz-IXgzup6xvBw096pUwAgOFPMxnKWMfyTL4dMtKeznPukuZYWO-uqVoZAmUoXnELo36g6h-nWZEy8tWVpKIROQPsIoTuHl6OfAvj9bjvwo-JPSSq6VfwBcEcQmFWgBfVIq%7EgheVttmc8hpw2pDPcMMk9XAFw2TwC8yxr1bormVlaaYdZSlCo6pMB5l2zFI2YSK2OJIHBCJj%7EQEN%7ELCrEIIECpKMTvIZc0P1zaq9D23xBhCK-n0j3xQyFuOAibPR7w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub:\n",
      "(MaxRetryError('HTTPSConnectionPool(host=\\'cdn-lfs-us-1.huggingface.co\\', port=443): Max retries exceeded with url: /repos/4f/e9/4fe94fab3c6a8bf97c3289fc6feb023e1504259a53971018d4b19f2f7ed06185/69f74147e3334731bc3a76048724833325d2ec74642fb52620eda87352e3d4f1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.bin%3B+filename%3D%22model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1720543701&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDU0MzcwMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRmL2U5LzRmZTk0ZmFiM2M2YThiZjk3YzMyODlmYzZmZWIwMjNlMTUwNDI1OWE1Mzk3MTAxOGQ0YjE5ZjJmN2VkMDYxODUvNjlmNzQxNDdlMzMzNDczMWJjM2E3NjA0ODcyNDgzMzMyNWQyZWM3NDY0MmZiNTI2MjBlZGE4NzM1MmUzZDRmMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=B83viReFoJgzkpt~j0~93lTXThXkc6LgseDICUy3FEd8iJakLQf0pY7PLXZ8q5-YrZcP8dJtLDBCXBy2Gq29Oz-IXgzup6xvBw096pUwAgOFPMxnKWMfyTL4dMtKeznPukuZYWO-uqVoZAmUoXnELo36g6h-nWZEy8tWVpKIROQPsIoTuHl6OfAvj9bjvwo-JPSSq6VfwBcEcQmFWgBfVIq~gheVttmc8hpw2pDPcMMk9XAFw2TwC8yxr1bormVlaaYdZSlCo6pMB5l2zFI2YSK2OJIHBCJj~QEN~LCrEIIECpKMTvIZc0P1zaq9D23xBhCK-n0j3xQyFuOAibPR7w__&Key-Pair-Id=K24J24Z295AEI9 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000014BBB037BC0>: Failed to resolve \\'cdn-lfs-us-1.huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 68c65b3d-193e-41f4-8184-6bccf1208396)')\n",
      "Trying to load the model directly from the local cache, if it exists.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open file 'model.bin' in model 'C:\\Users\\user\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-large-v3\\snapshots\\edaa852ec7e145841d8ffdb056a99866b5f0a478'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Run on GPU with FP16\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\faster_whisper\\transcribe.py:145\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[1;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only, files, **model_kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m download_model(\n\u001b[0;32m    140\u001b[0m         model_size_or_path,\n\u001b[0;32m    141\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    142\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mdownload_root,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mctranslate2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhisper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintra_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43minter_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m tokenizer_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_bytes:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open file 'model.bin' in model 'C:\\Users\\user\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-large-v3\\snapshots\\edaa852ec7e145841d8ffdb056a99866b5f0a478'"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C:\\Users\\user\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-large-v3\\snapshots\\edaa852ec7e145841d8ffdb056a99866b5f0a478'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "segments, info = model.transcribe(\"sample.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
